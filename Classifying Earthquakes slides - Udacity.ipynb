{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h1><center>Classifying Earthquakes:</center></h1>\n",
    "<h2><center>An Introduction to Recurrent Neural Networks using TensorFlow</center></h2>\n",
    "\n",
    "<h3><center>David M. Clark</center></h3>\n",
    "<h3><center>January 7, 2017</center></h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h2><center>Outline</center></h2>\n",
    "<div class=\"row\" style=\"font-size: 24px\">\n",
    "    <div class=\"col-md-12\">\n",
    "        <ul>\n",
    "            <li>Talk divided into two parts:</li><br>\n",
    "            <ol>\n",
    "                <li>Background: Introduction to neural networks and RNNs.</li>\n",
    "                <br><br>\n",
    "                <li>Code: Set up TensorFlow model and train it.</li>\n",
    "            </ol>\n",
    "        </ul>\n",
    "    </div>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h2><center>What is a neural network?</center></h2>\n",
    "<div class=\"row\" style=\"font-size: 24px\">\n",
    "    <div class=\"col-md-6\">\n",
    "        <ul>\n",
    "            <li>A type of machine learning based on how the brain works.</li><br>\n",
    "        <br>\n",
    "            <li>Input is passed through neurons, which decide how important it is related to the output.</li><br>\n",
    "        <br>\n",
    "            <li>Inputs are weighted and a bias term is applied.</li><br>\n",
    "        <br>\n",
    "            <li>Decisions are made using an activation function.</li><br>\n",
    "        </ul>\n",
    "    </div>\n",
    "    <div class=\"col-md-6\">\n",
    "        <img src=\"images/tikz0-142ppv5.png\" style=\"width:300px\"><br>\n",
    "        <img src=\"images/VqOpE-1c4xc4y-300x153.jpg\" style=\"width:300px\">\n",
    "    </div>\n",
    "</div>\n",
    "<div class=\"row\" style=\"font-size: 10px\">\n",
    "    <div class=\"col-md-12\">\n",
    "        <p><a href=\"http://http://neuralnetworksanddeeplearning.com/\">Neural Networks and Deep Learning</a>\n",
    "    </div>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h2><center>What is a neural network?</center></h2>\n",
    "<div class=\"row\" style=\"font-size: 24px\">\n",
    "    <div class=\"col-md-6\">\n",
    "        <ul>\n",
    "            <li>Many inputs can pass through a single neuron.</li>\n",
    "            <br>\n",
    "            <li>Hidden layer</li>\n",
    "            <ul>\n",
    "                <li>Layer of neurons between inputs and outputs.</li>\n",
    "                <li>More complex decision-making ability.</li>\n",
    "            </ul>\n",
    "            <br>\n",
    "            <li>Inputs, layers of neurons, outputs &#8658; neural network.</li>\n",
    "            <br>\n",
    "            <li>Deep learning</li>\n",
    "            <ul>\n",
    "                <li>Many hidden layers.</li>\n",
    "                <li>Can make very complex decisions.</li>\n",
    "            </ul>\n",
    "        </ul>\n",
    "    </div>\n",
    "    <div class=\"col-md-6\">\n",
    "        <img src=\"images/tikz41.png\" style=\"width:500px\"><br>\n",
    "    </div>\n",
    "</div>\n",
    "<div class=\"row\" style=\"font-size: 10px\">\n",
    "    <div class=\"col-md-12\">\n",
    "        <p><a href=\"http://http://neuralnetworksanddeeplearning.com/\">Neural Networks and Deep Learning</a>\n",
    "    </div>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h2><center>Types of Deep Learning</center></h2>\n",
    "<h3><center>Convolution Neural Networks</center></h3>\n",
    "<div class=\"row\" style=\"font-size: 24px\">\n",
    "    <div class=\"col-md-12\">\n",
    "        <img src=\"images/cnn_example_image.png\" style=\"width:800px\">\n",
    "    </div>\n",
    "</div>\n",
    "<br>\n",
    "<div class=\"row\" style=\"font-size: 24px\">\n",
    "    <div class=\"col-md-12\">\n",
    "        <ul>\n",
    "            <li>Neuron groups sample 2-dimensional plane.</li>\n",
    "            <li>Many layered</li>\n",
    "            <li>Feedforward neural network</li>\n",
    "            <li>Image recognition</li>\n",
    "        </ul>\n",
    "    </div>\n",
    "</div>\n",
    "<div class=\"row\" style=\"font-size: 10px\">\n",
    "    <div class=\"col-md-12\">\n",
    "        <p><a href=\"http://www.wildml.com/2015/11/understanding-convolutional-neural-networks-for-nlp/\">Understanding Convolution Neural Networks for NLP</a>, WildML, November 7, 2015\n",
    "    </div>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h2><center>Types of Deep Learning</center></h2>\n",
    "<h3><center>Recurrent Neural Networks</center></h3>\n",
    "<div class=\"row\" style=\"font-size: 24px\">\n",
    "    <div class=\"col-md-12\">\n",
    "        <img src=\"images/rnn_example_image.png\" style=\"width:600px\">\n",
    "    </div>\n",
    "</div>\n",
    "<br>\n",
    "<div class=\"row\" style=\"font-size: 24px\">\n",
    "    <div class=\"col-md-12\">\n",
    "        <ul>\n",
    "            <li>Usually single layered</li>\n",
    "            <li>Information pulled through network like a ticker tape.</li>\n",
    "            <li>State of RNN changes through time</li>\n",
    "            <li>Network can learn a sequence.</li>\n",
    "        </ul>\n",
    "    </div>\n",
    "</div>\n",
    "<div class=\"row\" style=\"font-size: 10px\">\n",
    "    <div class=\"col-md-12\">\n",
    "        <p><a href=\"http://colah.github.io/posts/2015-08-Understanding-LSTMs/\">Understanding LSTM Networks</a>, colah's blog, August 27, 2015\n",
    "    </div>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h2><center>Types of Recurrent Neural Networks</center></h2>\n",
    "<div class=\"row\" style=\"font-size: 24px\">\n",
    "    <div class=\"col-md-12\">\n",
    "        <img src=\"images/diags.jpeg\" style=\"width:800px\">\n",
    "    </div>\n",
    "</div>\n",
    "<div class=\"row\" style=\"font-size: 18px\">\n",
    "    <div class=\"col-md-2\">\n",
    "        <dl>\n",
    "            <dt>one to one</dt>\n",
    "            <dd style=\"padding: 0; margin: 0\">- image classification</dd>\n",
    "        </dl>\n",
    "    </div>\n",
    "    <div class=\"col-md-2\">\n",
    "        <dl>\n",
    "            <dt>one to many</dt>\n",
    "            <dd style=\"padding: 0; margin: 0\">- sentiment analysis</dd>\n",
    "        </dl>\n",
    "    </div>\n",
    "    <div class=\"col-md-2\">\n",
    "        <dl>\n",
    "            <dt>many to one</dt>\n",
    "            <dd style=\"padding: 0; margin: 0\">- sequence classification</dd>\n",
    "        </dl>\n",
    "    </div>\n",
    "    <div class=\"col-md-2\">\n",
    "        <dl>\n",
    "            <dt>many to many</dt>\n",
    "            <dd style=\"padding: 0; margin: 0\">- translation</dd>\n",
    "        </dl>\n",
    "    </div>\n",
    "    <div class=\"col-md-1\">\n",
    "        <p>\n",
    "    </div>\n",
    "    <div class=\"col-md-2\">\n",
    "        <dl>\n",
    "            <dt>many to many</dt>\n",
    "            <dd style=\"padding: 0; margin: 0\">- video classification</dd>\n",
    "        </dl>\n",
    "    </div>\n",
    "    <div class=\"col-md-1\">\n",
    "        <p>\n",
    "    </div>\n",
    "</div>\n",
    "<div class=\"row\" style=\"font-size: 24px\">\n",
    "    <div class=\"col-md-12\">\n",
    "        <p style=\"font-size: 10px\"><a href=\"http://karpathy.github.io/2015/05/21/rnn-effectiveness/\">The Unreasonable Effectiveness of Recurrent Neural Networks</a>, Andrej Karpathy blog, May 21, 2015\n",
    "    </div>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h2><center>RNN Concepts</center></h2>\n",
    "<div class=\"row\" style=\"font-size: 24px\">\n",
    "    <div class=\"col-md-12\">\n",
    "        <ul>\n",
    "            <li>Backpropagation through time (BPTT).</li>\n",
    "            <br><br>\n",
    "            <li>Vanishing/exploding gradients</li>\n",
    "            <br><br>\n",
    "            <li>LSTMs</li>\n",
    "        </ul>\n",
    "    </div>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h2><center>Backpropagation</center></h2>\n",
    "<div class=\"row\" style=\"font-size: 24px\">\n",
    "    <div class=\"col-md-12\">\n",
    "        <ul>\n",
    "            <li>Backpropagate errors through each layer in RNN.</li>\n",
    "            <ul>\n",
    "                <li>Number of layers = number of time steps in series.</li>\n",
    "                <li>Backpropagation Through Time (BPTT).</li>\n",
    "            </ul>\n",
    "            <br>\n",
    "            <li>Challenges:</li>\n",
    "                <ul>\n",
    "                <li>Difficult to train long series.</li>\n",
    "                <li>Shared weights.</li>\n",
    "                    <ul>\n",
    "                        <li>Slope of current gradient can directly affect slope of past gradients.</li>\n",
    "                    </ul>\n",
    "                    <li>Weight updates vs. accurate gradients.</li>\n",
    "                </ul>\n",
    "            <br>\n",
    "            <li>Solutions:</li>\n",
    "            <ul>\n",
    "                <li>Truncated backprogation</li>\n",
    "                <li>LSTMs</li>\n",
    "            </ul>\n",
    "        </ul>\n",
    "    </div>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "<h2><center>Backpropagation</center></h2>\n",
    "<div class=\"row\" style=\"font-size: 24px\">\n",
    "    <div class=\"col-md-12\">\n",
    "        <dl>\n",
    "            <dt>True backpropagation:</dt>\n",
    "        </dl>\n",
    "        <center><img src=\"images/RNN_true_truncated_backprop.png\" style=\"width:400px\"></center>\n",
    "        <br>\n",
    "        <dl>\n",
    "            <dt>TensorFlow style backpropagation:</dt>\n",
    "            <dd style=\"padding: 0; margin: 0\">- graph split into separate tensors</dd>\n",
    "            <dd style=\"padding: 0; margin: 0\">- each n backprop steps wide</dd>\n",
    "        </dl>\n",
    "        <center><img src=\"images/RNN_tf_truncated_backprop.png\" style=\"width:500px\"></center>\n",
    "    </div>\n",
    "</div>\n",
    "<div class=\"row\" style=\"font-size: 10px\">\n",
    "    <div class=\"col-md-12\">\n",
    "        <p><a href=\"http://r2rt.com/styles-of-truncated-backpropagation.html\">Styles of Truncated Backpropagation</a>, R2RT, July 19, 2016\n",
    "    </div>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h2><center>Vanishing/Exploding Gradients</center></h2>\n",
    "<div class=\"row\" style=\"font-size: 24px\">\n",
    "    <div class=\"col-md-12\">\n",
    "        <ul>\n",
    "            <li>Gradient can explode when backpropogation step is large.</li>\n",
    "            <ul>\n",
    "                <li>Clip gradients to prevent explosion.</li><br>\n",
    "            </ul>\n",
    "            <br>\n",
    "            <li>Vanishing gradients are more difficult to deal with.</li>\n",
    "            <ul>\n",
    "                <li>Good weight initialization important.</li>\n",
    "            </ul>\n",
    "            <br><br>\n",
    "            <li>What about variable gradients during training?</li>\n",
    "            <ul>\n",
    "                <li>LSTMs can solve this issue.</li><br>\n",
    "            </ul>\n",
    "        </ul>\n",
    "    </div>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h2><center>Long Short-Term Memory</center></h2>\n",
    "<br><br>\n",
    "<div class=\"row\" style=\"font-size: 24px\">\n",
    "    <div class=\"col-md-12\">\n",
    "        <ul>\n",
    "            <li>Basic principle - write down information to remember.</li><br>\n",
    "            <br>\n",
    "            <li>Main challenge - information overload.</li><br>\n",
    "        </ul>\n",
    "    </div>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h2><center>Long Short-Term Memory</center></h2>\n",
    "<br><br>\n",
    "<div class=\"row\" style=\"font-size: 24px\">\n",
    "    <div class=\"col-md-6\">\n",
    "        <ul>\n",
    "            <li>Overcoming LSTM challenges:</li><br>\n",
    "            <ul>\n",
    "                <li>Forget selectively.</li><br>\n",
    "                <li>Read selectively.</li><br>\n",
    "                <li>Write selectively.</li><br>\n",
    "            </ul>\n",
    "        </ul>\n",
    "    </div>\n",
    "    <div class=\"col-md-6\">\n",
    "        <ul>\n",
    "            <li>LSTM cell</li><br>\n",
    "            <ul>\n",
    "                <li>Forget gate.</li><br>\n",
    "                <li>Input gate.</li><br>\n",
    "                <li>Output gate.</li><br>\n",
    "            </ul>\n",
    "        </ul>\n",
    "    </div>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h2><center>Forget Gate</center></h2>\n",
    "<br><br>\n",
    "<div class=\"row\" style=\"font-size: 24px\">\n",
    "    <div class=\"col-md-6\">\n",
    "        <ul>\n",
    "            <li>Decide what information to remove from cell state.</li><br>\n",
    "            <br>\n",
    "            <li>Sigmoid layer.</li><br>\n",
    "            <br>\n",
    "        </ul>\n",
    "    </div>    \n",
    "    <div class=\"col-md-6\">\n",
    "        <img src=\"images/LSTM3-focus-f.png\" style=\"width:1000px\">\n",
    "    </div>\n",
    "</div>\n",
    "<div class=\"row\" style=\"font-size: 10px\">\n",
    "    <div class=\"col-md-12\">\n",
    "        <p><a href=\"http://colah.github.io/posts/2015-08-Understanding-LSTMs/\">Understanding LSTM Networks</a>, colah's blog, August 27, 2015\n",
    "    </div>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h2><center>Input Gate</center></h2>\n",
    "<div class=\"row\" style=\"font-size: 24px\">\n",
    "    <div class=\"col-md-6\">\n",
    "        <ul>\n",
    "            <li>Decide what information to store in cell state.</li><br>\n",
    "            <br>\n",
    "        </ul>\n",
    "        <ol>\n",
    "            <li>Decide what to update.</li>\n",
    "            <ul>\n",
    "                <li>sigmoid layer.</li><br>\n",
    "            </ul>\n",
    "            <br>\n",
    "            <li>Create candidate values for cell state.</li>\n",
    "            <ul>\n",
    "                <li>tanh layer.</li><br>\n",
    "            </ul>\n",
    "            <br>\n",
    "        </ol>\n",
    "    </div>\n",
    "    <div class=\"col-md-6\">\n",
    "        <img src=\"images/LSTM3-focus-i.png\" style=\"width:1000px\">\n",
    "    </div>\n",
    "</div>\n",
    "<div class=\"row\" style=\"font-size: 10px\">\n",
    "    <div class=\"col-md-12\">\n",
    "        <p><a href=\"http://colah.github.io/posts/2015-08-Understanding-LSTMs/\">Understanding LSTM Networks</a>, colah's blog, August 27, 2015\n",
    "    </div>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h2><center>Update Cell State</center></h2>\n",
    "<div class=\"row\" style=\"font-size: 24px\">\n",
    "    <div class=\"col-md-6\">\n",
    "        <ol>\n",
    "            <li>Remove forgotten information.</li>\n",
    "            <ul>\n",
    "                <li>Multiply $f_t$ by old cell state.</li><br>\n",
    "            </ul>\n",
    "            <br>\n",
    "            <li>Add new candidate values scaled by their importance.</li>\n",
    "            <ul>\n",
    "                <li>Add $i_t\\ast\\tilde{C}_t$</li><br>\n",
    "            </ul>\n",
    "            <br>\n",
    "        </ol>\n",
    "    </div>\n",
    "    <div class=\"col-md-6\">\n",
    "        <img src=\"images/LSTM3-focus-C.png\" style=\"width:1000px\">\n",
    "    </div>\n",
    "</div>\n",
    "<div class=\"row\" style=\"font-size: 10px\">\n",
    "    <div class=\"col-md-12\">\n",
    "        <p><a href=\"http://colah.github.io/posts/2015-08-Understanding-LSTMs/\">Understanding LSTM Networks</a>, colah's blog, August 27, 2015\n",
    "    </div>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h2><center>Output Gate</center></h2>\n",
    "<div class=\"row\" style=\"font-size: 24px\">\n",
    "    <div class=\"col-md-6\">\n",
    "        <ol>\n",
    "            <li>Decide what information from cell state to output.</li>\n",
    "            <ul>\n",
    "                <li>sigmoid layer.</li><br>\n",
    "            </ul>\n",
    "            <br>\n",
    "            <li>Filter out pertinent information.</li>\n",
    "            <ul>\n",
    "                <li>pass cell state through tanh layer.</li><br>\n",
    "                <li>mulitply by sigmoid layer output.</li><br>\n",
    "            </ul>\n",
    "        </ol>\n",
    "    </div>\n",
    "    <div class=\"col-md-6\">\n",
    "        <img src=\"images/LSTM3-focus-o.png\" style=\"width:1000px\">\n",
    "    </div>\n",
    "</div>\n",
    "<div class=\"row\" style=\"font-size: 10px\">\n",
    "    <div class=\"col-md-12\">\n",
    "        <p><a href=\"http://colah.github.io/posts/2015-08-Understanding-LSTMs/\">Understanding LSTM Networks</a>, colah's blog, August 27, 2015\n",
    "    </div>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h2><center>Mulitple Layers</center></h2>\n",
    "<div class=\"row\" style=\"font-size: 24px\">\n",
    "    <div class=\"col-md-6\">\n",
    "        <ul>\n",
    "            <li>Mulitiple LSTM cells can be wrapped together.</li><br>\n",
    "            <ul>\n",
    "                <li>Behaves like a single LSTM cell.</li><br>\n",
    "                <li>Increases model complexity.</li>\n",
    "            </ul>\n",
    "        </ul>\n",
    "    </div>\n",
    "    <div class=\"col-md-6\">\n",
    "        <img src=\"images/RNN_MultiRNNCellGrouped.png\" style=\"width:200px\" align=\"right\">\n",
    "    </div>\n",
    "</div>\n",
    "<div class=\"row\" style=\"font-size: 10px\">\n",
    "    <div class=\"col-md-12\">\n",
    "        <p><a href=\"http://r2rt.com/recurrent-neural-networks-in-tensorflow-ii.html\">Recurrent Neural Networks in Tensorflow II</a>, R2RT, July 25, 2016\n",
    "    </div>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h1><center>TensorFlow Model</center></h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h2><center>What is TensorFlow?</center></h2>\n",
    "<div class=\"row\" style=\"font-size: 24px\">\n",
    "    <div class=\"col-md-12\">\n",
    "        <ul>\n",
    "            <li>Developed by the Google Brain Team.</li>\n",
    "            <ul>\n",
    "                <li>Graph-based.</li>\n",
    "                <li>Nodes are operations.</li>\n",
    "                <li>Edges are multi-dimensional arrays called tensors.</li>\n",
    "            </ul>\n",
    "            <br>\n",
    "            <li>All operations are done outside of Python.</li>\n",
    "            <br>\n",
    "            <li>Inputs are stored in a <strong><code>placeholder()</code></strong> or <strong><code>Variable()</code></strong></li>\n",
    "            <ul>\n",
    "                <li><strong><code>placeholder()</code></strong>: fixed input.</li>\n",
    "                <li><strong><code>Variable()</code></strong>: variable input.</li>\n",
    "            </ul>\n",
    "            <br>\n",
    "            <li>Inputs are populated during a TensorFlow session.</li>\n",
    "        </ul>\n",
    "    </div>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h2><center>Earthquake Dataset</center></h2>\n",
    "<div class=\"row\" style=\"font-size: 24px\">\n",
    "    <div class=\"col-md-6\">\n",
    "        <ul>\n",
    "            <li>Dataset taken from the UCR Timeseries Classification Archive <span style=\"font-size: 18px\">(http://www.cs.ucr.edu/~eamonn/time_series_data/)</span>.</li>\n",
    "            <br>\n",
    "            <li>Consists of timeseries for two types of earthquakes.</li>\n",
    "            <br>\n",
    "            <li>Goal: Produce a model that can differentiate between each earthquake type.</li>\n",
    "        </ul>\n",
    "    </div>\n",
    "    <div class=\"col-md-6\">\n",
    "        <img src=\"images/UCR_time_series.png\" style=\"width:300px\" align=\"right\">\n",
    "    </div>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "# Import statements\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.framework import ops\n",
    "from matplotlib import pyplot as plt\n",
    "from natsort import natsorted\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h2><center>Data Preparation</center></h2>\n",
    "### Load the data\n",
    "Read in the training and test sets into Pandas DataFrames."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 138 entries, 0 to 137\n",
      "Columns: 513 entries, 0 to -0.26927.475\n",
      "dtypes: float64(512), int64(1)\n",
      "memory usage: 553.2 KB\n"
     ]
    }
   ],
   "source": [
    "training_set = pd.read_csv('data/Earthquakes_TRAIN', sep=',')\n",
    "test_validation_set = pd.read_csv('data/Earthquakes_TEST', sep=',')\n",
    "\n",
    "training_set.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Brief data exploration\n",
    "Let's see how many unique labels there are in the training and test/validation data sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In the training set, there are 103 '0' classes and 35 '1' classes.\n"
     ]
    }
   ],
   "source": [
    "y_train = training_set.iloc[:,0]\n",
    "zero_label = len(y_train[y_train == 0])\n",
    "one_label = len(y_train[y_train == 1])\n",
    "print(\"In the training set, there are {} '0' classes and {} '1' classes.\".format(zero_label,one_label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In the test/validation set, there are 264 '0' classes and 57 '1' classes.\n"
     ]
    }
   ],
   "source": [
    "y_test_validation = test_validation_set.iloc[:,0]\n",
    "zero_label = len(y_test_validation[y_test_validation == 0])\n",
    "one_label = len(y_test_validation[y_test_validation == 1])\n",
    "print(\"In the test/validation set, there are {} '0' classes and {} '1' classes.\".format(zero_label,one_label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "def random_data_split(df):\n",
    "    \n",
    "    classes = df.iloc[:,0]\n",
    "    unique_classes = classes.unique()\n",
    "    \n",
    "    number_of_classes_list = []\n",
    "    for c in unique_classes:\n",
    "        number_of_classes = len(classes[classes == c])\n",
    "        number_of_classes_list.append(number_of_classes)\n",
    "        \n",
    "    smallest_class_index = np.argmin(np.array(number_of_classes_list))\n",
    "    smallest_class = unique_classes[smallest_class_index]\n",
    "    \n",
    "    # Store smallest class in a DataFrame\n",
    "    smallest_class_mask = (df.iloc[:,0] == smallest_class).tolist()\n",
    "    df_small = df.iloc[smallest_class_mask,:]\n",
    "    smallest_class_size = len(df_small)\n",
    "    \n",
    "    # Select only classes larger than the smallest class\n",
    "    larger_classes = unique_classes[unique_classes != smallest_class]\n",
    "    larger_classes_mask = (df.iloc[:,0] != smallest_class).tolist()\n",
    "    df_larger = df.iloc[larger_classes_mask,:]\n",
    "    \n",
    "    # Loop through the larger classes and select a random set of size equal to the smallest class size\n",
    "    for lc in larger_classes:\n",
    "        class_mask = (df_larger.iloc[:,0] == lc).tolist()\n",
    "        df_get_class = df_larger.iloc[class_mask,:]\n",
    "        df_sample = df_get_class.sample(n=smallest_class_size)\n",
    "        df_small = df_small.append(df_sample)\n",
    "    \n",
    "    return df_small"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "# Set only the first positive value to 1 and then increment each subsequent positive value by 1.\n",
    "def increment_positives(df):\n",
    "    mask = df.ix[:,1:] > 0\n",
    "    mask_array = mask.as_matrix()\n",
    "    for i in range(df.shape[0]):\n",
    "        positives_array = np.arange(len(np.where(mask_array[i,:])[0])) + 1\n",
    "        df.iloc[i, np.where(mask_array[i,:])[0]+1] = np.arange(len(np.where(mask_array[i,:])[0])) + 1\n",
    "        # df.iloc[i, np.where(mask_array[i,:] == False)[0]+1] = np.nan\n",
    "    return df\n",
    "\n",
    "training_set = increment_positives(training_set)\n",
    "test_validation_set = increment_positives(test_validation_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h2><center>Data Preparation</center></h2>\n",
    "### Evenly split labels\n",
    "- Uneven distribution of unique labels is bad for modeling and can lead to bias for a specific label.\n",
    "- To correct this, I resampled the datasets to make an even distribution of unique labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "training_set_resampled = random_data_split(training_set)\n",
    "new_training_index = np.arange(len(training_set_resampled))\n",
    "training_set_resampled = training_set_resampled.set_index(new_training_index).copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 35 entries for class 1 in the training set.\n",
      "There are 35 entries for class 0 in the training set.\n"
     ]
    }
   ],
   "source": [
    "y_training_resampled = training_set_resampled.iloc[:,0]\n",
    "unique_training_labels_resampled = y_training_resampled.unique()\n",
    "\n",
    "for c in unique_training_labels_resampled:\n",
    "    label_count = len(y_training_resampled[y_training_resampled == c])\n",
    "    print('There are {} entries for class {} in the training set.'.format(label_count, c))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "test_validation_set_resampled = random_data_split(test_validation_set)\n",
    "new_test_validation_index = np.arange(len(test_validation_set_resampled))\n",
    "test_validation_set_resampled = test_validation_set_resampled.set_index(new_test_validation_index).copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 57 entries for class 1 in the test/validation set.\n",
      "There are 57 entries for class 0 in the test/validation set.\n"
     ]
    }
   ],
   "source": [
    "y_test_validation_resampled = test_validation_set_resampled.iloc[:,0]\n",
    "unique_test_validation_labels_resampled = y_test_validation_resampled.unique()\n",
    "\n",
    "for c in unique_test_validation_labels_resampled:\n",
    "    label_count = len(y_test_validation_resampled[y_test_validation_resampled == c])\n",
    "    print('There are {} entries for class {} in the test/validation set.'.format(label_count, c))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h2><center>Data Preparation</center></h2>\n",
    "### Split `test_validation_set` into `test_set` and `validation_set`\n",
    "- **`validation_set`**: used to evaluate model fit during training.\n",
    "- **`test_set`**: used to measure final model accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "split_index = len(test_validation_set_resampled) // 2\n",
    "test_set_resampled = test_validation_set_resampled.iloc[0:split_index,:].copy()\n",
    "validation_set_resampled = test_validation_set_resampled.iloc[split_index:,:].copy()\n",
    "new_validation_set_resampled_index = np.arange(len(validation_set_resampled))\n",
    "validation_set_resampled = validation_set_resampled.set_index(new_validation_set_resampled_index).copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h2><center>Model Preparation</center></h2>\n",
    "### Create batches\n",
    "Train the model on small batches of the training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# Function to take a random batch of data from the training set\n",
    "def make_batch(dataset, batch_size, back_prop_steps):\n",
    "    \n",
    "    num_rows, num_columns = dataset.shape\n",
    "    \n",
    "    bp_start_i = np.random.choice(num_columns-back_prop_steps,1)[0]\n",
    "    \n",
    "    # Make sure bp_start is greater than zero so that it won't include labels column\n",
    "    while bp_start_i < 1:\n",
    "        bp_start_i = np.random.choice(num_columns-back_prop_steps,1)[0]\n",
    "        \n",
    "    bp_end_i = bp_start_i + back_prop_steps\n",
    "    \n",
    "    random_batch = dataset.sample(n=batch_size)\n",
    "    \n",
    "    X_batch = random_batch.iloc[:,bp_start_i:bp_end_i]\n",
    "    y_batch = random_batch.iloc[:,0].values\n",
    "    \n",
    "    return X_batch, y_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "# Function to print hyperparameters to a directory\n",
    "def save_hyperparameters(hyperparam_dict, training_step_list, final_accuracy):\n",
    "    \n",
    "    cwd = os.getcwd()\n",
    "    fpath = cwd+'/tmp/params'\n",
    "    try:\n",
    "        dirlist = os.listdir(fpath)\n",
    "        dirlist_parsed = [x.split('_') for x in dirlist]\n",
    "        dirlist_parsed_prefix = [x.split('_')[0] for x in dirlist]\n",
    "        dirlist_parsed_suffix = [x.split('_')[-1] for x in dirlist]\n",
    "\n",
    "        dirarray = np.array(dirlist)\n",
    "        dirarray_parsed_prefix = np.array(dirlist_parsed_prefix)\n",
    "        dirarray_sorted_suffix = np.array(natsorted(dirlist_parsed_suffix))\n",
    "    \n",
    "        num_run_dirs = np.sum(dirarray_parsed_prefix == 'run')\n",
    "    \n",
    "    except FileNotFoundError:\n",
    "        os.mkdir(fpath)\n",
    "        num_run_dirs = 0\n",
    "\n",
    "    # Check if run_1 directory exisits\n",
    "    if num_run_dirs == 0:\n",
    "        next_run_directory = '/run_1'\n",
    "    else:\n",
    "        previous_run_number = np.int(dirarray_sorted_suffix[-1])\n",
    "        next_run = previous_run_number + 1\n",
    "        next_run_string = np.str(next_run)\n",
    "        next_run_directory = '/run_'+next_run_string\n",
    "        \n",
    "    os.mkdir(fpath+next_run_directory)    \n",
    "    fo = open(fpath+next_run_directory+'/hyperparameters.txt', \"w\")\n",
    "    for key, value in hyperparam_dict.items():\n",
    "        fo.write(key+': '+np.str(value)+'\\n')\n",
    "    fo.write('\\n')\n",
    "    for list_item in training_step_list:\n",
    "        fo.write(list_item+'\\n')\n",
    "    fo.write(\"The final accuracy is {:3f}.\".format(final_accuracy))\n",
    "    fo.close()\n",
    "    \n",
    "    print('Saving hyperparameters to tmp/params{}/'.format(next_run_directory))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "# Function to print parameters to a directory\n",
    "def create_log_directory():\n",
    "    \n",
    "    cwd = os.getcwd()\n",
    "    fpath = cwd+'/tmp/logs'\n",
    "    try:\n",
    "        dirlist = os.listdir(fpath)\n",
    "        dirlist_parsed = [x.split('_') for x in dirlist]\n",
    "        dirlist_parsed_prefix = [x.split('_')[0] for x in dirlist]\n",
    "        dirlist_parsed_suffix = [x.split('_')[-1] for x in dirlist]\n",
    "\n",
    "        dirarray = np.array(dirlist)\n",
    "        dirarray_parsed_prefix = np.array(dirlist_parsed_prefix)\n",
    "        dirarray_sorted_suffix = np.array(natsorted(dirlist_parsed_suffix))\n",
    "    \n",
    "        num_run_dirs = np.sum(dirarray_parsed_prefix == 'run')\n",
    "    \n",
    "    except FileNotFoundError:\n",
    "        # os.mkdir(fpath)\n",
    "        os.mkdir(cwd+'/tmp')\n",
    "        os.mkdir(cwd+'/tmp/logs')\n",
    "        num_run_dirs = 0\n",
    "\n",
    "    # Check if run_1 directory exisits\n",
    "    if num_run_dirs == 0:\n",
    "        os.mkdir(fpath+'/run_1')\n",
    "        log_directory = 'tmp/logs/run_1'\n",
    "    else:\n",
    "        previous_run_number = np.int(dirarray_sorted_suffix[-1])\n",
    "        next_run = previous_run_number + 1\n",
    "        next_run_string = np.str(next_run)\n",
    "        next_run_directory = '/run_'+next_run_string\n",
    "        os.mkdir(fpath+next_run_directory)\n",
    "        log_directory = 'tmp/logs/run_'+next_run_string\n",
    "\n",
    "    print('Saving summaries to '+log_directory+'/')    \n",
    "        \n",
    "    return log_directory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h2><center>Model Preparation</center></h2>\n",
    "### Define hyperparameters\n",
    "Organized in dictionary to allow easy logging of values while searching for best model parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# Define the hyperparameters\n",
    "hyperparam_dict = dict(\n",
    "    number_of_classes = len(unique_training_labels_resampled),\n",
    "    batch_size = 14,\n",
    "    back_prop_steps = 100,\n",
    "    lstm_layers = 2,\n",
    "    lstm_cell_units = 5,\n",
    "    drop_out = 0.9,\n",
    "    clipping_ratio = 5,\n",
    "    learning_rate = 8e-3,\n",
    "    training_iterations = 2000\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h2><center>Model Preparation</center></h2>\n",
    "### Define TensorFlow placeholders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "def reset_graph():\n",
    "    if 'sess' in globals() and sess:\n",
    "        sess.close()\n",
    "    tf.reset_default_graph()\n",
    "\n",
    "# Reset graph if session isn't closed\n",
    "reset_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# Define TensorFlow placeholders\n",
    "X = tf.placeholder(tf.float32,\n",
    "                   [None, hyperparam_dict['back_prop_steps']],\n",
    "                   name = 'Features')\n",
    "y = tf.placeholder(tf.int64,\n",
    "                   [None], \n",
    "                   name='Labels')\n",
    "keep_probability = tf.placeholder('float', name = 'drop_out')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h2><center>Model Preparation</center></h2>\n",
    "### Create LSTM cell\n",
    "This includes dropout and multiple layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "def create_lstm_cell(lstm_cell_units, keep_probability, lstm_layers, batch_size, X):\n",
    "    cell = tf.nn.rnn_cell.LSTMCell(lstm_cell_units, state_is_tuple=True)\n",
    "    cell = tf.nn.rnn_cell.DropoutWrapper(cell, input_keep_prob=keep_probability)\n",
    "    cell = tf.nn.rnn_cell.MultiRNNCell([cell] * lstm_layers, state_is_tuple=True)\n",
    "    cell = tf.nn.rnn_cell.DropoutWrapper(cell, output_keep_prob=keep_probability)\n",
    "    initial_state = cell.zero_state(batch_size, tf.float32)\n",
    "    cell_inputs = tf.expand_dims(X, 2)\n",
    "    \n",
    "    return cell, cell_inputs, initial_state"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h2><center>Model Preparation</center></h2>\n",
    "### Define the LSTM State\n",
    "Here is where the RNN is filled out. The previously defined LSTM cells are now spread the length of the number of backpropagtion steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "def set_lstm_state(cell, cell_inputs, initial_state, back_prop_steps):\n",
    "    cell_outputs = []\n",
    "    with tf.variable_scope('LSTM_state'):\n",
    "        for step in range(back_prop_steps):\n",
    "            if step > 0:\n",
    "                tf.get_variable_scope().reuse_variables()\n",
    "            (cell_output, state) = cell(cell_inputs[:, step, :], initial_state)\n",
    "            cell_outputs.append(cell_output)\n",
    "        output = tf.reduce_mean(tf.pack(cell_outputs), 0)\n",
    "        \n",
    "    return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h2><center>Model Preparation</center></h2>\n",
    "### Create softmax layer\n",
    "The LSTM cells will be placed in a softmax layer. This will allow the RNN to learn categorical data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "def softmax_layer(lstm_cell_units, number_of_classes, output):\n",
    "    W = tf.Variable(tf.truncated_normal([lstm_cell_units, number_of_classes], \n",
    "                                        stddev=1.0), \n",
    "                    name='weights', dtype=tf.float32, trainable=True)\n",
    "    b = tf.Variable(tf.zeros([number_of_classes]), \n",
    "                    name='biases', dtype=tf.float32, trainable=True)\n",
    "    output_X_W = tf.matmul(output, W, name='multiply')\n",
    "    logits = tf.add(output_X_W, b, name='add')\n",
    "    \n",
    "    return logits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h2><center>Model Preparation</center></h2>\n",
    "### Define cost function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "def define_cost_function(logits, y, batch_size):\n",
    "    \n",
    "    loss = tf.nn.sparse_softmax_cross_entropy_with_logits(logits, y, \n",
    "                                                          name='cross_entropy')\n",
    "    cost = tf.reduce_sum(loss) / batch_size\n",
    "    \n",
    "    return cost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h2><center>Model Preparation</center></h2>\n",
    "### Create training step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "def train(cost, learning_rate, clipping_ratio):\n",
    "    training_variables = tf.trainable_variables()\n",
    "    computed_gradientes = tf.gradients(cost, training_variables)\n",
    "    clipped_gradients, _ = tf.clip_by_global_norm(computed_gradientes, \n",
    "                                                  clipping_ratio)\n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate)\n",
    "    gradients = list(zip(clipped_gradients, training_variables))\n",
    "    training_step = optimizer.apply_gradients(gradients)\n",
    "    # Create histograms for variables, gradients and gradient norms. Plots displayed in TensorBoard.\n",
    "    for gradient, variable in gradients:\n",
    "        if isinstance(gradient, ops.IndexedSlices):\n",
    "            gradient_values = gradient.values\n",
    "        else:\n",
    "            gradient_values = gradient\n",
    "        tf.histogram_summary(variable.name, variable)\n",
    "        tf.histogram_summary(variable.name + \"/gradients\", gradient_values)\n",
    "        tf.histogram_summary(variable.name + \"/gradient_norm\", \n",
    "                             tf.global_norm([gradient_values]))\n",
    "\n",
    "    return training_step"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h2><center>Model Preparation</center></h2>\n",
    "### Check model accuracy during training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "def check_model_accuracy(logits, y):\n",
    "    correct_prediction = tf.equal(tf.argmax(logits,1), y)\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, \"float\"), \n",
    "                              name='accuracy')\n",
    "    \n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h2><center>Model Preparation</center></h2>\n",
    "### Compute the final model accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# Function to compute final model accuracy\n",
    "def compute_final_accuracy(test_set, batch_size, back_prop_steps):\n",
    "    test_rows = test_set.shape[0]\n",
    "    number_of_batches = np.floor(test_rows/batch_size)\n",
    "    test_accuracy = np.zeros(number_of_batches)\n",
    "    for i in range(int(number_of_batches)):\n",
    "        X_batch, y_batch = make_batch(test_set, batch_size, back_prop_steps)\n",
    "        test_accuracy[i] = sess.run(accuracy, \n",
    "                                    feed_dict = {X: X_batch, \n",
    "                                                 y: y_batch,\n",
    "                                                 keep_probability: 1})\n",
    "    \n",
    "    return np.mean(test_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h2><center>Setup TensorFlow Graph</center></h2>\n",
    "<br>\n",
    "Now that we have defined the functions needed for the TensorFlow graph, we can create it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# Create LSTM cell\n",
    "with tf.name_scope(\"LSTM_cell\") as scope:\n",
    "    cell, cell_inputs, initial_state = create_lstm_cell(hyperparam_dict['lstm_cell_units'],\n",
    "                                                        keep_probability,\n",
    "                                                        hyperparam_dict['lstm_layers'],\n",
    "                                                        hyperparam_dict['batch_size'], X)\n",
    "# Set LSTM state\n",
    "with tf.name_scope(\"LSTM_state\") as scope:\n",
    "    output = set_lstm_state(cell, cell_inputs, initial_state, hyperparam_dict['back_prop_steps'])\n",
    "\n",
    "# Create softmax layer\n",
    "with tf.name_scope(\"softmax_layer\") as scope:\n",
    "    logits = softmax_layer(hyperparam_dict['lstm_cell_units'], \n",
    "                           hyperparam_dict['number_of_classes'], \n",
    "                           output)\n",
    "\n",
    "# Define cost function\n",
    "with tf.name_scope(\"cost_function\") as scope:\n",
    "    cost = define_cost_function(logits, \n",
    "                                y, \n",
    "                                hyperparam_dict['batch_size'])\n",
    "    tf.scalar_summary(\"cost\", cost)\n",
    "\n",
    "# Define training step\n",
    "with tf.name_scope(\"training\") as scope:\n",
    "    training_step = train(cost, \n",
    "                          hyperparam_dict['learning_rate'], \n",
    "                          hyperparam_dict['clipping_ratio'])\n",
    "\n",
    "# Calculate model accuracy\n",
    "with tf.name_scope(\"accuracy\") as scope:\n",
    "    accuracy = check_model_accuracy(logits, y)\n",
    "    tf.scalar_summary(\"accuracy\", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h2><center>Train the Model</center></h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving summaries to tmp/logs/run_14/\n",
      "Resampling training set every 5 steps.\n",
      "Step 0 of 2000. Cost: [training = 0.708, training_ma = 0.693, validation = 0.691], Validation Accuracy: 0.429\n",
      "Step 100 of 2000. Cost: [training = 0.679, training_ma = 0.693, validation = 0.657], Validation Accuracy: 1.000\n",
      "Step 200 of 2000. Cost: [training = 0.667, training_ma = 0.682, validation = 0.632], Validation Accuracy: 0.500\n",
      "Step 300 of 2000. Cost: [training = 0.505, training_ma = 0.662, validation = 0.723], Validation Accuracy: 0.571\n",
      "Step 400 of 2000. Cost: [training = 0.750, training_ma = 0.640, validation = 0.926], Validation Accuracy: 0.286\n",
      "Step 500 of 2000. Cost: [training = 0.674, training_ma = 0.628, validation = 0.571], Validation Accuracy: 0.643\n",
      "Step 600 of 2000. Cost: [training = 0.645, training_ma = 0.627, validation = 0.721], Validation Accuracy: 0.500\n",
      "Step 700 of 2000. Cost: [training = 0.661, training_ma = 0.627, validation = 0.757], Validation Accuracy: 0.500\n",
      "Step 800 of 2000. Cost: [training = 0.722, training_ma = 0.623, validation = 0.960], Validation Accuracy: 0.357\n",
      "Step 900 of 2000. Cost: [training = 0.619, training_ma = 0.616, validation = 1.018], Validation Accuracy: 0.357\n",
      "Step 1000 of 2000. Cost: [training = 0.698, training_ma = 0.624, validation = 0.787], Validation Accuracy: 0.357\n",
      "Step 1100 of 2000. Cost: [training = 0.825, training_ma = 0.625, validation = 0.910], Validation Accuracy: 0.286\n",
      "Step 1200 of 2000. Cost: [training = 0.686, training_ma = 0.620, validation = 0.687], Validation Accuracy: 0.500\n",
      "Step 1300 of 2000. Cost: [training = 0.706, training_ma = 0.625, validation = 0.767], Validation Accuracy: 0.429\n",
      "Step 1400 of 2000. Cost: [training = 0.610, training_ma = 0.630, validation = 0.817], Validation Accuracy: 0.357\n",
      "Step 1500 of 2000. Cost: [training = 0.531, training_ma = 0.623, validation = 0.750], Validation Accuracy: 0.429\n",
      "Step 1600 of 2000. Cost: [training = 0.534, training_ma = 0.617, validation = 0.461], Validation Accuracy: 0.714\n",
      "Step 1700 of 2000. Cost: [training = 0.689, training_ma = 0.616, validation = 0.790], Validation Accuracy: 0.357\n",
      "Step 1800 of 2000. Cost: [training = 0.633, training_ma = 0.622, validation = 0.638], Validation Accuracy: 0.571\n",
      "Step 1900 of 2000. Cost: [training = 0.526, training_ma = 0.622, validation = 0.772], Validation Accuracy: 0.429\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dave/anaconda/envs/python3/lib/python3.5/site-packages/ipykernel/__main__.py:5: VisibleDeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The final accuracy is 0.839.\n",
      "Saving hyperparameters to tmp/params/run_14/\n"
     ]
    }
   ],
   "source": [
    "# Merge summaries for TensorBoard\n",
    "merged_summaries = tf.merge_all_summaries()\n",
    "\n",
    "# Start a TensorFlow session\n",
    "with tf.Session() as sess:\n",
    "    \n",
    "    log_directory = create_log_directory()\n",
    "    summary_writer = tf.train.SummaryWriter(log_directory, sess.graph)\n",
    "    \n",
    "    tf.initialize_all_variables().run()\n",
    "\n",
    "    step = 0\n",
    "    training_step_list = []\n",
    "    cost_train_ma = -np.log(1/float(hyperparam_dict['number_of_classes'])+1e-9)\n",
    "    training_set_resampled = random_data_split(training_set)\n",
    "    training_set_size = training_set_resampled.shape[0]\n",
    "    resample_frequency = training_set_size // hyperparam_dict['batch_size']\n",
    "    print(\"Resampling training set every {} steps.\".format(resample_frequency))\n",
    "    for i in range(hyperparam_dict['training_iterations']):\n",
    "        # Generate a new training set for a given frequency\n",
    "        if i % resample_frequency == 0:\n",
    "            training_set_resampled = random_data_split(training_set)\n",
    "            new_training_index = np.arange(len(training_set_resampled))\n",
    "            training_set_resampled = training_set_resampled.set_index(new_training_index).copy()\n",
    "\n",
    "        # Sample batch for training\n",
    "        X_batch, y_batch = make_batch(training_set_resampled, \n",
    "                                      hyperparam_dict['batch_size'], \n",
    "                                      hyperparam_dict['back_prop_steps'])\n",
    "\n",
    "        # Train the model\n",
    "        cost_train, _ = sess.run([cost, training_step], \n",
    "                                 feed_dict = {X:X_batch, \n",
    "                                              y:y_batch, \n",
    "                                              keep_probability: hyperparam_dict['drop_out']}\n",
    "                                )\n",
    "        cost_train_ma = cost_train_ma*0.99 + cost_train*0.01\n",
    "        if i%100 == 0:\n",
    "\n",
    "            # Evaluate validation performance\n",
    "            X_batch, y_batch = make_batch(validation_set_resampled, \n",
    "                                          hyperparam_dict['batch_size'], \n",
    "                                          hyperparam_dict['back_prop_steps'])\n",
    "            result = sess.run([cost, merged_summaries, accuracy], \n",
    "                              feed_dict = {X: X_batch, \n",
    "                                           y: y_batch,\n",
    "                                           keep_probability: 1},\n",
    "                             )\n",
    "            cost_validation = result[0]\n",
    "            accuracy_validation = result[2]\n",
    "            training_step_stats = 'Step {:d} of {:d}. Cost: [training = {:0.3f}, training_ma = {:0.3f}, validation = {:0.3f}], Validation Accuracy: {:0.3f}'.format(i,hyperparam_dict['training_iterations'],cost_train,cost_train_ma,cost_validation,accuracy_validation)\n",
    "            print(training_step_stats)\n",
    "            training_step_list.append(training_step_stats)\n",
    "\n",
    "            # Save model parametes for TensorBoard\n",
    "            summary_str = result[1]\n",
    "            summary_writer.add_summary(summary_str, i)\n",
    "            summary_writer.flush()\n",
    "\n",
    "            step += 1\n",
    "\n",
    "    final_accuracy = compute_final_accuracy(test_set_resampled, \n",
    "                                            hyperparam_dict['batch_size'], \n",
    "                                            hyperparam_dict['back_prop_steps'])\n",
    "    print(\"The final accuracy is {:0.3f}.\".format(final_accuracy))\n",
    "    \n",
    "    # Save hyperparameters used for model fitting\n",
    "    save_hyperparameters(hyperparam_dict, training_step_list, final_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "To compile this notebook as an html slide presentation run the following command: \n",
    "\n",
    "`$ jupyter nbconvert Classifying\\ Earthquakes\\ slides.ipynb --to slides --post serve`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python [conda env:python3]",
   "language": "python",
   "name": "conda-env-python3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
