{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classifying Earthquakes\n",
    "In this notebook, I classify earthquakes using an LSTM RNN TensorFlow model. The data is taken from the [UCR Time Series Classification Archive](http://www.cs.ucr.edu/~eamonn/time_series_data/) (Yanping Chen, Eamonn Keogh, Bing Hu, Nurjahan Begum, Anthony Bagnall, Abdullah Mueen and Gustavo Batista (2015))."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.framework import ops\n",
    "from matplotlib import pyplot as plt\n",
    "from natsort import natsorted\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation\n",
    "### Load the Data\n",
    "I load the data into Pandas DataFrames."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "training_set = pd.read_csv('data/Earthquakes_TRAIN', sep=',')\n",
    "test_validation_set = pd.read_csv('data/Earthquakes_TEST', sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 138 entries, 0 to 137\n",
      "Columns: 513 entries, 0 to -0.26927.475\n",
      "dtypes: float64(512), int64(1)\n",
      "memory usage: 553.2 KB\n"
     ]
    }
   ],
   "source": [
    "training_set.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_set.iloc[:,0].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Exploration\n",
    "Let's separate the labels and features from both the training set and test/validation set. I can then investigate trends for each data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train = training_set.iloc[:,1:]\n",
    "y_train = training_set.iloc[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_test_validation = test_validation_set.iloc[:,1:]\n",
    "y_test_validation = test_validation_set.iloc[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 2 unique training classes, which are [1, 0].\n"
     ]
    }
   ],
   "source": [
    "unique_training_classes =  y_train.unique().tolist()\n",
    "print(\"There are {} unique training classes, which are {}.\".format(len(unique_training_classes), unique_training_classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 2 unique test classes, which are [0, 1].\n"
     ]
    }
   ],
   "source": [
    "unique_test_validation_classes =  y_test_validation.unique().tolist()\n",
    "print(\"There are {} unique test classes, which are {}.\".format(len(unique_test_validation_classes), unique_test_validation_classes))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Good, all classes in the training and test sets are in agreement, as expected. Now, let's investigate the number of unique classes for each data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In the training set, there are 103 '0' classes and 35 '1' classes.\n"
     ]
    }
   ],
   "source": [
    "print(\"In the training set, there are {} '0' classes and {} '1' classes.\".format(len(y_train[y_train == 0]), len(y_train[y_train == 1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In the test/validation set, there are 264 '0' classes and 57 '1' classes.\n"
     ]
    }
   ],
   "source": [
    "print(\"In the test/validation set, there are {} '0' classes and {} '1' classes.\".format(len(y_test_validation[y_test_validation == 0]), len(y_test_validation[y_test_validation == 1])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is an unequal number of entries between the two different classes. This could be problematic during the modeling phase as it could lead to a bias. I will address this issue duing data preparation below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Visualization\n",
    "Let's plot a row of the training set and view what the data looks like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1065e08d0>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAiIAAAFkCAYAAAAdXVDGAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nkMGgECGEEELIYPxfbuGHBUtH5jAAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1065bee48>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "mask = training_set.iloc[:,0] == 0\n",
    "subset = training_set.ix[mask == True, :].copy()\n",
    "subset.iloc[0,:].plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation\n",
    "### Evenly split labels.\n",
    "Here I define a function to randomly choose values from the larger of the two classes and produce a dataset with equal quantities of both classes. This will be done for both the train set and test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def random_data_split(df):\n",
    "    \n",
    "    classes = df.iloc[:,0]\n",
    "    unique_classes = classes.unique()\n",
    "    \n",
    "    number_of_classes_list = []\n",
    "    for c in unique_classes:\n",
    "        number_of_classes = len(classes[classes == c])\n",
    "        number_of_classes_list.append(number_of_classes)\n",
    "        \n",
    "    smallest_class_index = np.argmin(np.array(number_of_classes_list))\n",
    "    smallest_class = unique_classes[smallest_class_index]\n",
    "    \n",
    "    # Store smallest class in a DataFrame\n",
    "    smallest_class_mask = (df.iloc[:,0] == smallest_class).tolist()\n",
    "    df_small = df.iloc[smallest_class_mask,:]\n",
    "    smallest_class_size = len(df_small)\n",
    "    \n",
    "    # Select only classes larger than the smallest class\n",
    "    larger_classes = unique_classes[unique_classes != smallest_class]\n",
    "    larger_classes_mask = (df.iloc[:,0] != smallest_class).tolist()\n",
    "    df_larger = df.iloc[larger_classes_mask,:]\n",
    "    \n",
    "    # Loop through the larger classes and select a random set of size equal to the smallest class size\n",
    "    for lc in larger_classes:\n",
    "        class_mask = (df_larger.iloc[:,0] == lc).tolist()\n",
    "        df_get_class = df_larger.iloc[class_mask,:]\n",
    "        df_sample = df_get_class.sample(n=smallest_class_size)\n",
    "        df_small = df_small.append(df_sample)\n",
    "    \n",
    "    return df_small"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "training_set_resampled = random_data_split(training_set)\n",
    "new_training_index = np.arange(len(training_set_resampled))\n",
    "training_set_resampled = training_set_resampled.set_index(new_training_index).copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 35 entries for class 1 in the training set.\n",
      "There are 35 entries for class 0 in the training set.\n"
     ]
    }
   ],
   "source": [
    "y_training_resampled = training_set_resampled.iloc[:,0]\n",
    "unique_training_labels_resampled = y_training_resampled.unique()\n",
    "\n",
    "for c in unique_training_labels_resampled:\n",
    "    label_count = len(y_training_resampled[y_training_resampled == c])\n",
    "    print('There are {} entries for class {} in the training set.'.format(label_count, c))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_validation_set_resampled = random_data_split(test_validation_set)\n",
    "new_test_validation_index = np.arange(len(test_validation_set_resampled))\n",
    "test_validation_set_resampled = test_validation_set_resampled.set_index(new_test_validation_index).copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 57 entries for class 1 in the test/validation set.\n",
      "There are 57 entries for class 0 in the test/validation set.\n"
     ]
    }
   ],
   "source": [
    "y_test_validation_resampled = test_validation_set_resampled.iloc[:,0]\n",
    "unique_test_validation_labels_resampled = y_test_validation_resampled.unique()\n",
    "\n",
    "for c in unique_test_validation_labels_resampled:\n",
    "    label_count = len(y_test_validation_resampled[y_test_validation_resampled == c])\n",
    "    print('There are {} entries for class {} in the test/validation set.'.format(label_count, c))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Good. Now I have a way to ensure that each class is represented equally in the analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split test_validation_set into test_set and validation_set\n",
    "Now I split the test_validation_set equally into a test_set and validation_set. The validation_set will be used to test the model accuracy during training, while the test_set will be used to measure the final model accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "split_index = len(test_validation_set_resampled) // 2\n",
    "test_set_resampled = test_validation_set_resampled.iloc[0:split_index,:].copy()\n",
    "validation_set_resampled = test_validation_set_resampled.iloc[split_index:,:].copy()\n",
    "new_validation_set_resampled_index = np.arange(len(validation_set_resampled))\n",
    "validation_set_resampled = validation_set_resampled.set_index(new_validation_set_resampled_index).copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Function to take a random batch of data from the training set\n",
    "def make_batch(full_training_set, batch_size, back_prop_steps):\n",
    "    \n",
    "    num_rows, num_columns = full_training_set.shape\n",
    "    \n",
    "    bp_start_i = np.random.choice(num_columns-back_prop_steps,1)[0]\n",
    "    bp_end_i = bp_start_i + back_prop_steps\n",
    "    \n",
    "    random_batch = full_training_set.sample(n=batch_size)\n",
    "    \n",
    "    X_batch = random_batch.iloc[0:,bp_start_i:bp_end_i]\n",
    "    y_batch_array = random_batch.iloc[:,0].values\n",
    "    y_batch = np.array([y_batch_array]*back_prop_steps)\n",
    "    \n",
    "    return X_batch, y_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Function to print hyperparameters to a directory\n",
    "def save_hyperparameters(hyperparam_dict, training_step_list, final_accuracy):\n",
    "    \n",
    "    cwd = os.getcwd()\n",
    "    fpath = cwd+'/tmp/params'\n",
    "    try:\n",
    "        dirlist = os.listdir(fpath)\n",
    "        dirlist_parsed = [x.split('_') for x in dirlist]\n",
    "        dirlist_parsed_prefix = [x.split('_')[0] for x in dirlist]\n",
    "        dirlist_parsed_suffix = [x.split('_')[-1] for x in dirlist]\n",
    "\n",
    "        dirarray = np.array(dirlist)\n",
    "        dirarray_parsed_prefix = np.array(dirlist_parsed_prefix)\n",
    "        dirarray_sorted_suffix = np.array(natsorted(dirlist_parsed_suffix))\n",
    "    \n",
    "        num_run_dirs = np.sum(dirarray_parsed_prefix == 'run')\n",
    "    \n",
    "    except FileNotFoundError:\n",
    "        os.mkdir(fpath)\n",
    "        num_run_dirs = 0\n",
    "\n",
    "    # Check if run_1 directory exisits\n",
    "    if num_run_dirs == 0:\n",
    "        next_run_directory = '/run_1'\n",
    "    else:\n",
    "        previous_run_number = np.int(dirarray_sorted_suffix[-1])\n",
    "        next_run = previous_run_number + 1\n",
    "        next_run_string = np.str(next_run)\n",
    "        next_run_directory = '/run_'+next_run_string\n",
    "        \n",
    "    os.mkdir(fpath+next_run_directory)    \n",
    "    fo = open(fpath+next_run_directory+'/hyperparameters.txt', \"w\")\n",
    "    for key, value in hyperparam_dict.items():\n",
    "        fo.write(key+': '+np.str(value)+'\\n')\n",
    "    fo.write('\\n')\n",
    "    for list_item in training_step_list:\n",
    "        fo.write(list_item+'\\n')\n",
    "    fo.write(\"The final accuracy is {:3f}.\".format(final_accuracy))\n",
    "    fo.close()\n",
    "    \n",
    "    print('Saving hyperparameters to tmp/params{}/'.format(next_run_directory))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Function to print parameters to a directory\n",
    "def create_log_directory():\n",
    "    \n",
    "    cwd = os.getcwd()\n",
    "    fpath = cwd+'/tmp/logs'\n",
    "    try:\n",
    "        dirlist = os.listdir(fpath)\n",
    "        dirlist_parsed = [x.split('_') for x in dirlist]\n",
    "        dirlist_parsed_prefix = [x.split('_')[0] for x in dirlist]\n",
    "        dirlist_parsed_suffix = [x.split('_')[-1] for x in dirlist]\n",
    "\n",
    "        dirarray = np.array(dirlist)\n",
    "        dirarray_parsed_prefix = np.array(dirlist_parsed_prefix)\n",
    "        dirarray_sorted_suffix = np.array(natsorted(dirlist_parsed_suffix))\n",
    "    \n",
    "        num_run_dirs = np.sum(dirarray_parsed_prefix == 'run')\n",
    "    \n",
    "    except FileNotFoundError:\n",
    "        os.mkdir(fpath)\n",
    "        num_run_dirs = 0\n",
    "\n",
    "    # Check if run_1 directory exisits\n",
    "    if num_run_dirs == 0:\n",
    "        os.mkdir(fpath+'/run_1')\n",
    "        log_directory = 'tmp/logs/run_1'\n",
    "    else:\n",
    "        previous_run_number = np.int(dirarray_sorted_suffix[-1])\n",
    "        next_run = previous_run_number + 1\n",
    "        next_run_string = np.str(next_run)\n",
    "        next_run_directory = '/run_'+next_run_string\n",
    "        os.mkdir(fpath+next_run_directory)\n",
    "        log_directory = 'tmp/logs/run_'+next_run_string\n",
    "\n",
    "    print('Saving summaries to '+log_directory+'/')    \n",
    "        \n",
    "    return log_directory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the hyperparameters\n",
    "Organized in dictionary to allow easy logging of values while searching for best model parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Define the hyperparameters\n",
    "hyperparam_dict = dict(\n",
    "    number_of_classes = len(unique_training_labels_resampled),\n",
    "    batch_size = 10,\n",
    "    back_prop_steps = 50,\n",
    "    lstm_layers = 2,\n",
    "    lstm_cell_units = 7,\n",
    "    drop_out = 0.8,\n",
    "    clipping_ratio = 5,\n",
    "    learning_rate = 2e-6,\n",
    "    training_iterations = 2000\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define TensorFlow placeholders\n",
    "X = tf.placeholder(tf.float32,\n",
    "                   [None, hyperparam_dict['back_prop_steps']],\n",
    "                   name = 'Features')\n",
    "y = tf.placeholder(tf.int64,\n",
    "                   [None, hyperparam_dict['back_prop_steps']], \n",
    "                   name='Labels')\n",
    "keep_probability = tf.constant(hyperparam_dict['drop_out'])\n",
    "\n",
    "# Expand dimensions of features placeholder\n",
    "X_expanded = tf.expand_dims(X, 2)\n",
    "\n",
    "# Reshaped labels placeholder\n",
    "y_reshaped = tf.reshape(y, [-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the LSTM cell\n",
    "This includes dropout and multiple layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def create_lstm_cell(lstm_cell_units, keep_probability, lstm_layers, batch_size, X):\n",
    "    cell = tf.nn.rnn_cell.LSTMCell(lstm_cell_units, state_is_tuple=True)\n",
    "    cell = tf.nn.rnn_cell.DropoutWrapper(cell, input_keep_prob=keep_probability)\n",
    "    cell = tf.nn.rnn_cell.MultiRNNCell([cell] * lstm_layers, state_is_tuple=True)\n",
    "    cell = tf.nn.rnn_cell.DropoutWrapper(cell, output_keep_prob=keep_probability)\n",
    "    init_state = cell.zero_state(batch_size, tf.float32)\n",
    "    cell_outputs, state = tf.nn.dynamic_rnn(cell, X, initial_state=init_state)\n",
    "    cell_outputs = tf.reshape(cell_outputs, [-1, lstm_cell_units])\n",
    "    \n",
    "    return cell_outputs, state"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the softmax layer\n",
    "The LSTM cells will be placed in a softmax layer. This will allow the RNN to learn categorical data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def softmax_layer(lstm_cell_units, number_of_classes, cell_outputs):\n",
    "    W = tf.Variable(tf.truncated_normal([lstm_cell_units, number_of_classes], \n",
    "                                        stddev=1.0), \n",
    "                    name='weights', dtype=tf.float32, trainable=True)\n",
    "    b = tf.Variable(tf.zeros([number_of_classes]), \n",
    "                    name='biases', dtype=tf.float32, trainable=True)\n",
    "    logits = tf.add(tf.matmul(cell_outputs, W, name='multiply'), b, name='add')\n",
    "    \n",
    "    return logits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the cost function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def define_cost_function(logits, y, batch_size):\n",
    "    loss = tf.nn.sparse_softmax_cross_entropy_with_logits(logits, y, \n",
    "                                                          name='cross_entropy')\n",
    "    cost = tf.reduce_mean(loss) / batch_size\n",
    "    \n",
    "    return cost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the training step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def train(cost, learning_rate, clipping_ratio):\n",
    "    training_variables = tf.trainable_variables()\n",
    "    computed_gradientes = tf.gradients(cost, training_variables)\n",
    "    clipped_gradients, _ = tf.clip_by_global_norm(computed_gradientes, \n",
    "                                                  clipping_ratio)\n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate)\n",
    "    gradients = list(zip(clipped_gradients, training_variables))\n",
    "    training_step = optimizer.apply_gradients(gradients)\n",
    "    # Create histograms for variables, gradients and gradient norms. Plots displayed in TensorBoard.\n",
    "    for gradient, variable in gradients:\n",
    "        if isinstance(gradient, ops.IndexedSlices):\n",
    "            gradient_values = gradient.values\n",
    "        else:\n",
    "            gradient_values = gradient\n",
    "        tf.histogram_summary(variable.name, variable)\n",
    "        tf.histogram_summary(variable.name + \"/gradients\", gradient_values)\n",
    "        tf.histogram_summary(variable.name + \"/gradient_norm\", \n",
    "                             tf.global_norm([gradient_values]))\n",
    "\n",
    "    return training_step"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check model accuracy during training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def check_model_accuracy(logits, y):\n",
    "    correct_prediction = tf.equal(tf.argmax(logits,1), y)\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, \"float\"), \n",
    "                              name='accuracy')\n",
    "    \n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute the final model accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Function to compute final model accuracy\n",
    "def compute_final_accuracy(test_set, batch_size, back_prop_steps):\n",
    "    test_rows = test_set.shape[0]\n",
    "    number_of_batches = np.floor(test_rows/batch_size)\n",
    "    test_accuracy = np.zeros(number_of_batches)\n",
    "    for i in range(int(number_of_batches)):\n",
    "        X_batch, y_batch = make_batch(test_set, batch_size, back_prop_steps)\n",
    "        X_batch_expanded = np.expand_dims(X_batch, axis=2)\n",
    "        y_batch_reshaped = np.ravel(y_batch)\n",
    "        test_accuracy[i] = sess.run(accuracy, \n",
    "                                    feed_dict = {X_expanded: X_batch_expanded, \n",
    "                                                 y_reshaped: y_batch_reshaped,\n",
    "                                                 keep_probability: 1})\n",
    "    \n",
    "    return np.mean(test_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup the TensorFlow Graph\n",
    "Now that we have defined the functions needed for the TensorFlow graph, we can create it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Create LSTM Cell\n",
    "with tf.name_scope(\"LSTM\") as scope:\n",
    "    cell_outputs, state = create_lstm_cell(hyperparam_dict['lstm_cell_units'], \n",
    "                                           keep_probability, \n",
    "                                           hyperparam_dict['lstm_layers'], \n",
    "                                           hyperparam_dict['batch_size'], \n",
    "                                           X_expanded)\n",
    "\n",
    "# Create softmax layer\n",
    "with tf.name_scope(\"softmax_layer\") as scope:\n",
    "    logits = softmax_layer(hyperparam_dict['lstm_cell_units'], \n",
    "                           hyperparam_dict['number_of_classes'], \n",
    "                           cell_outputs)\n",
    "\n",
    "# Define cost function\n",
    "with tf.name_scope(\"cost_function\") as scope:\n",
    "    cost = define_cost_function(logits, \n",
    "                                y_reshaped, \n",
    "                                hyperparam_dict['batch_size'])\n",
    "    tf.scalar_summary(\"cost\", cost)\n",
    "\n",
    "# Define training step\n",
    "with tf.name_scope(\"training\") as scope:\n",
    "    training_step = train(cost, \n",
    "                          hyperparam_dict['learning_rate'], \n",
    "                          hyperparam_dict['clipping_ratio'])\n",
    "\n",
    "# Calculate model accuracy\n",
    "with tf.name_scope(\"accuracy\") as scope:\n",
    "    accuracy = check_model_accuracy(logits, y_reshaped)\n",
    "    tf.scalar_summary(\"accuracy\", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving summaries to tmp/logs/run_78/\n",
      "Training set resampled every 28 steps.\n",
      "Step 0 of 2000: training cost = 0.072, validation cost = 0.080, validation accuracy = 0.300.\n",
      "Step 100 of 2000: training cost = 0.068, validation cost = 0.087, validation accuracy = 0.212.\n",
      "Step 200 of 2000: training cost = 0.069, validation cost = 0.079, validation accuracy = 0.270.\n",
      "Step 300 of 2000: training cost = 0.077, validation cost = 0.083, validation accuracy = 0.160.\n",
      "Step 400 of 2000: training cost = 0.068, validation cost = 0.076, validation accuracy = 0.380.\n",
      "Step 500 of 2000: training cost = 0.067, validation cost = 0.078, validation accuracy = 0.296.\n",
      "Step 600 of 2000: training cost = 0.073, validation cost = 0.080, validation accuracy = 0.200.\n",
      "Step 700 of 2000: training cost = 0.072, validation cost = 0.082, validation accuracy = 0.202.\n",
      "Step 800 of 2000: training cost = 0.071, validation cost = 0.076, validation accuracy = 0.262.\n",
      "Step 900 of 2000: training cost = 0.076, validation cost = 0.083, validation accuracy = 0.138.\n",
      "Step 1000 of 2000: training cost = 0.071, validation cost = 0.078, validation accuracy = 0.286.\n",
      "Step 1100 of 2000: training cost = 0.068, validation cost = 0.078, validation accuracy = 0.258.\n",
      "Step 1200 of 2000: training cost = 0.070, validation cost = 0.077, validation accuracy = 0.214.\n",
      "Step 1300 of 2000: training cost = 0.072, validation cost = 0.080, validation accuracy = 0.170.\n",
      "Step 1400 of 2000: training cost = 0.069, validation cost = 0.076, validation accuracy = 0.272.\n",
      "Step 1500 of 2000: training cost = 0.075, validation cost = 0.076, validation accuracy = 0.312.\n",
      "Step 1600 of 2000: training cost = 0.071, validation cost = 0.077, validation accuracy = 0.304.\n",
      "Step 1700 of 2000: training cost = 0.068, validation cost = 0.084, validation accuracy = 0.160.\n",
      "Step 1800 of 2000: training cost = 0.073, validation cost = 0.076, validation accuracy = 0.330.\n",
      "Step 1900 of 2000: training cost = 0.073, validation cost = 0.079, validation accuracy = 0.226.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dave/anaconda/envs/python3/lib/python3.5/site-packages/ipykernel/__main__.py:5: VisibleDeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The final accuracy is 0.708400.\n",
      "Saving hyperparameters to tmp/params/run_78/\n"
     ]
    }
   ],
   "source": [
    "# Merge summaries for TensorBoard\n",
    "merged_summaries = tf.merge_all_summaries()\n",
    "\n",
    "# Start a TensorFlow session\n",
    "with tf.Session() as sess:\n",
    "    \n",
    "    log_directory = create_log_directory()\n",
    "    summary_writer = tf.train.SummaryWriter(log_directory, sess.graph)\n",
    "    \n",
    "    tf.initialize_all_variables().run()\n",
    "\n",
    "    step = 0\n",
    "    training_step_list = []\n",
    "    cost_train_ma = -np.log(1/float(hyperparam_dict['number_of_classes'])+1e-9)\n",
    "    training_set_resampled = random_data_split(training_set)\n",
    "    training_set_size = training_set_resampled.shape[0]\n",
    "    resample_frequency = hyperparam_dict['training_iterations'] // training_set_size\n",
    "    print(\"Training set resampled every {} steps.\".format(resample_frequency))\n",
    "    for i in range(hyperparam_dict['training_iterations']):\n",
    "        # Generate a new training set for a given frequency\n",
    "        if i % resample_frequency == 0:\n",
    "            training_set_resampled = random_data_split(training_set)\n",
    "            new_training_index = np.arange(len(training_set_resampled))\n",
    "            training_set_resampled = training_set_resampled.set_index(new_training_index).copy()\n",
    "\n",
    "        # Sample batch for training\n",
    "        X_batch, y_batch = make_batch(training_set_resampled, \n",
    "                                      hyperparam_dict['batch_size'], \n",
    "                                      hyperparam_dict['back_prop_steps'])\n",
    "        X_batch_expanded = np.expand_dims(X_batch, axis=2)\n",
    "        y_batch_reshaped = np.ravel(y_batch)\n",
    "\n",
    "        # Train the model\n",
    "        cost_train, _ = sess.run([cost, training_step], \n",
    "                                 feed_dict = {X_expanded:X_batch_expanded, \n",
    "                                              y_reshaped:y_batch_reshaped, \n",
    "                                              keep_probability: hyperparam_dict['drop_out']}\n",
    "                                )\n",
    "        cost_train_ma = cost_train_ma*0.99 + cost_train*0.01\n",
    "        if i%100 == 0:\n",
    "\n",
    "            # Evaluate validation performance\n",
    "            X_batch, y_batch = make_batch(validation_set_resampled, \n",
    "                                          hyperparam_dict['batch_size'], \n",
    "                                          hyperparam_dict['back_prop_steps'])\n",
    "            X_batch_expanded = np.expand_dims(X_batch, axis=2)\n",
    "            y_batch_reshaped = np.ravel(y_batch)\n",
    "            result = sess.run([cost, merged_summaries, accuracy], \n",
    "                              feed_dict = {X_expanded: X_batch_expanded, \n",
    "                                           y_reshaped: y_batch_reshaped,\n",
    "                                           keep_probability: 1},\n",
    "                             )\n",
    "            cost_validation = result[0]\n",
    "            accuracy_validation = result[2]\n",
    "            # cost_validation = cost\n",
    "            # accuracy_validation = acc\n",
    "            training_step_stats = 'Step {:d} of {:d}: training cost = {:0.3f}, validation cost = {:0.3f}, validation accuracy = {:0.3f}.'.format(i,hyperparam_dict['training_iterations'],cost_train,cost_validation,accuracy_validation)\n",
    "            print(training_step_stats)\n",
    "            training_step_list.append(training_step_stats)\n",
    "\n",
    "            # Save model parametes for TensorBoard\n",
    "            summary_str = result[1]\n",
    "            summary_writer.add_summary(summary_str, i)\n",
    "            summary_writer.flush()\n",
    "\n",
    "            step += 1\n",
    "\n",
    "    final_accuracy = compute_final_accuracy(test_set_resampled, \n",
    "                                            hyperparam_dict['batch_size'], \n",
    "                                            hyperparam_dict['back_prop_steps'])\n",
    "    print(\"The final accuracy is {:3f}.\".format(final_accuracy))\n",
    "    \n",
    "    # Save hyperparameters used for model fitting\n",
    "    save_hyperparameters(hyperparam_dict, training_step_list, final_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:python3]",
   "language": "python",
   "name": "conda-env-python3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
